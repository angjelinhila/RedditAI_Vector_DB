{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/nr9m6qhj5592lvmkl5rls47w0000gn/T/ipykernel_3177/1802079138.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                           comments\n",
      "0  6qgmm  [{'id': 'c04lkn0', 'ups': 1.0, 'edited': False...\n",
      "1  6y98d                                                 []\n",
      "2  76liu                                                 []\n",
      "3  76ljt  [{'id': 'c05u1zt', 'ups': 1.0, 'edited': False...\n",
      "4  773i4                                                 []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the data\n",
    "comments = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/artificial_comments.json\")])\n",
    "submissions = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/artificial_submissions.json\")])\n",
    "\n",
    "# Extract submission_id from parent_id in comments\n",
    "#comments[\"submission_id\"] = comments[\"parent_id\"].apply(lambda x: x.split(\"_\")[1] if x.startswith(\"t3_\") else None)\n",
    "comments[\"submission_id\"] = comments[\"parent_id\"].astype(str).apply(lambda x: x.split(\"_\")[1] if x.startswith(\"t3_\") else None)\n",
    "\n",
    "\n",
    "# Group comments by submission_id (ensuring metadata retention)\n",
    "grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n",
    "\n",
    "# Function to nest comments under corresponding submissions\n",
    "def nest_comments(submission):\n",
    "    submission_id = submission[\"id\"]\n",
    "    submission[\"comments\"] = grouped_comments.get(submission_id, [])  # Retain full comment structure\n",
    "    return submission\n",
    "\n",
    "# Apply nesting\n",
    "submissions = submissions.apply(nest_comments, axis=1)\n",
    "\n",
    "# Save as JSONL format for compatibility with preprocessing scripts\n",
    "with open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Processed/nested_submissions_with_comments.json\", \"w\") as outfile:\n",
    "    for record in submissions.to_dict(orient=\"records\"):\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "# Display a preview of the nested data\n",
    "print(submissions[[\"id\", \"comments\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/nr9m6qhj5592lvmkl5rls47w0000gn/T/ipykernel_3468/926766853.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id comments\n",
      "0  4i43xg       []\n",
      "1  4okjlz       []\n",
      "2  562kgb       []\n",
      "3  564ss8       []\n",
      "4  567us4       []\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "comments = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/artificialinteligence_comments.json\")])\n",
    "submissions = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/artificialinteligence_submissions.json\")])\n",
    "\n",
    "# Extract submission_id from parent_id in comments\n",
    "comments[\"submission_id\"] = comments[\"parent_id\"].astype(str).apply(lambda x: x.split(\"_\")[1] if x.startswith(\"t3_\") else None)\n",
    "\n",
    "# Group comments by submission_id (ensuring metadata retention)\n",
    "grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n",
    "\n",
    "# Function to nest comments under corresponding submissions\n",
    "def nest_comments(submission):\n",
    "    submission_id = submission[\"id\"]\n",
    "    submission[\"comments\"] = grouped_comments.get(submission_id, [])  # Retain full comment structure\n",
    "    return submission\n",
    "\n",
    "# Apply nesting\n",
    "submissions = submissions.apply(nest_comments, axis=1)\n",
    "\n",
    "# Save as JSONL format for compatibility with preprocessing scripts\n",
    "with open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Processed/artificialint_nested_submissions_with_comments.json\", \"w\") as outfile:\n",
    "    for record in submissions.to_dict(orient=\"records\"):\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "# Display a preview of the nested data\n",
    "print(submissions[[\"id\", \"comments\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "comments = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/chatgpt_comments.json\")])\n",
    "submissions = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/chatgpt_submissions.json\")])\n",
    "\n",
    "# Extract submission_id from parent_id in comments\n",
    "comments[\"submission_id\"] = comments[\"parent_id\"].astype(str).apply(lambda x: x.split(\"_\")[1] if x.startswith(\"t3_\") else None)\n",
    "\n",
    "# Group comments by submission_id (ensuring metadata retention)\n",
    "grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n",
    "\n",
    "# Function to nest comments under corresponding submissions\n",
    "def nest_comments(submission):\n",
    "    submission_id = submission[\"id\"]\n",
    "    submission[\"comments\"] = grouped_comments.get(submission_id, [])  # Retain full comment structure\n",
    "    return submission\n",
    "\n",
    "# Apply nesting\n",
    "submissions = submissions.apply(nest_comments, axis=1)\n",
    "\n",
    "# Save as JSONL format for compatibility with preprocessing scripts\n",
    "with open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Processed/chatgpt_nested_submissions_with_comments.json\", \"w\") as outfile:\n",
    "    for record in submissions.to_dict(orient=\"records\"):\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "# Display a preview of the nested data\n",
    "print(submissions[[\"id\", \"comments\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the data efficiently\n",
    "with open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/chatgpt_comments.json\") as f:\n",
    "    comments = [json.loads(line) for line in f]\n",
    "\n",
    "with open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/chatgpt_submissions.json\") as f:\n",
    "    submissions = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert to DataFrame\n",
    "comments_df = pd.DataFrame(comments)\n",
    "submissions_df = pd.DataFrame(submissions)\n",
    "\n",
    "# Ensure parent_id is a string and extract submission_id\n",
    "comments_df[\"submission_id\"] = comments_df[\"parent_id\"].astype(str).apply(lambda x: x.split(\"_\")[1] if x.startswith(\"t3_\") else None)\n",
    "\n",
    "# Convert comments into a dictionary mapping submission_id â†’ list of comments\n",
    "grouped_comments = {}\n",
    "for comment in comments:\n",
    "    submission_id = comment.get(\"parent_id\", \"\").split(\"_\")[1] if str(comment.get(\"parent_id\", \"\")).startswith(\"t3_\") else None\n",
    "    if submission_id:\n",
    "        if submission_id not in grouped_comments:\n",
    "            grouped_comments[submission_id] = []\n",
    "        grouped_comments[submission_id].append(comment)\n",
    "\n",
    "# Attach nested comments to submissions\n",
    "for submission in submissions:\n",
    "    submission_id = submission[\"id\"]\n",
    "    submission[\"comments\"] = grouped_comments.get(submission_id, [])\n",
    "\n",
    "# Save as JSONL format\n",
    "output_file = \"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Processed/chatgpt_nested_submissions_with_comments.json\"\n",
    "with open(output_file, \"w\") as outfile:\n",
    "    for record in submissions:\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "print(f\"Saved nested data to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/nr9m6qhj5592lvmkl5rls47w0000gn/T/ipykernel_6171/3627453822.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                           comments\n",
      "0  3wfly4  [{'distinguished': None, 'body': 'I knew this ...\n",
      "1  3wfmr4  [{'distinguished': None, 'body': 'I'm so happy...\n",
      "2  3wg5u0                                                 []\n",
      "3  3wgd2v                                                 []\n",
      "4  3wgd8x                                                 []\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "comments = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/openai_comments.json\")])\n",
    "submissions = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/openai_submissions.json\")])\n",
    "\n",
    "# Extract submission_id from parent_id in comments\n",
    "comments[\"submission_id\"] = comments[\"parent_id\"].astype(str).apply(lambda x: x.split(\"_\")[1] if x.startswith(\"t3_\") else None)\n",
    "\n",
    "# Group comments by submission_id (ensuring metadata retention)\n",
    "grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n",
    "\n",
    "# Function to nest comments under corresponding submissions\n",
    "def nest_comments(submission):\n",
    "    submission_id = submission[\"id\"]\n",
    "    submission[\"comments\"] = grouped_comments.get(submission_id, [])  # Retain full comment structure\n",
    "    return submission\n",
    "\n",
    "# Apply nesting\n",
    "submissions = submissions.apply(nest_comments, axis=1)\n",
    "\n",
    "# Save as JSONL format for compatibility with preprocessing scripts\n",
    "with open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Processed/openai_nested_submissions_with_comments.json\", \"w\") as outfile:\n",
    "    for record in submissions.to_dict(orient=\"records\"):\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "# Display a preview of the nested data\n",
    "print(submissions[[\"id\", \"comments\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "comments = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/singularity_comments.json\")])\n",
    "submissions = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/singularity_submissions.json\")])\n",
    "\n",
    "# Extract submission_id from parent_id in comments\n",
    "comments[\"submission_id\"] = comments[\"parent_id\"].astype(str).apply(lambda x: x.split(\"_\")[1] if x.startswith(\"t3_\") else None)\n",
    "\n",
    "# Group comments by submission_id (ensuring metadata retention)\n",
    "grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n",
    "\n",
    "# Function to nest comments under corresponding submissions\n",
    "def nest_comments(submission):\n",
    "    submission_id = submission[\"id\"]\n",
    "    submission[\"comments\"] = grouped_comments.get(submission_id, [])  # Retain full comment structure\n",
    "    return submission\n",
    "\n",
    "# Apply nesting\n",
    "submissions = submissions.apply(nest_comments, axis=1)\n",
    "\n",
    "# Save as JSONL format for compatibility with preprocessing scripts\n",
    "with open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Processed/singularity_nested_submissions_with_comments.json\", \"w\") as outfile:\n",
    "    for record in submissions.to_dict(orient=\"records\"):\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "# Display a preview of the nested data\n",
    "print(submissions[[\"id\", \"comments\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "comments = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/transhumannism_comments.json\")])\n",
    "submissions = pd.DataFrame([json.loads(line) for line in open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Raw/transhumannism_submissions.json\")])\n",
    "\n",
    "# Extract submission_id from parent_id in comments\n",
    "comments[\"submission_id\"] = comments[\"parent_id\"].astype(str).apply(lambda x: x.split(\"_\")[1] if x.startswith(\"t3_\") else None)\n",
    "\n",
    "# Group comments by submission_id (ensuring metadata retention)\n",
    "grouped_comments = comments.groupby(\"submission_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n",
    "\n",
    "# Function to nest comments under corresponding submissions\n",
    "def nest_comments(submission):\n",
    "    submission_id = submission[\"id\"]\n",
    "    submission[\"comments\"] = grouped_comments.get(submission_id, [])  # Retain full comment structure\n",
    "    return submission\n",
    "\n",
    "# Apply nesting\n",
    "submissions = submissions.apply(nest_comments, axis=1)\n",
    "\n",
    "# Save as JSONL format for compatibility with preprocessing scripts\n",
    "with open(\"/Users/angjelin/Library/CloudStorage/Box-Box/Reddit Vector DB/Data/Processed/singularity_nested_submissions_with_comments.json\", \"w\") as outfile:\n",
    "    for record in submissions.to_dict(orient=\"records\"):\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "# Display a preview of the nested data\n",
    "print(submissions[[\"id\", \"comments\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
